{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12c466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports (patched)\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, OrdinalEncoder, FunctionTransformer, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e5a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility + device\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pin = (device.type == 'cuda')\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6436ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (175341, 45) test: (82332, 45)\n",
      "  attack_cat  label\n",
      "0     Normal      0\n",
      "1     Normal      0\n",
      "2     Normal      0\n",
      "3     Normal      0\n",
      "4     Normal      0\n"
     ]
    }
   ],
   "source": [
    "# Load UNSW-NB15\n",
    "PROJECT_ROOT = os.path.abspath('..')\n",
    "train_path = os.path.join(PROJECT_ROOT, 'data', 'unsw-nb15', 'raw', 'UNSW_NB15_training-set.csv')\n",
    "test_path  = os.path.join(PROJECT_ROOT, 'data', 'unsw-nb15', 'raw', 'UNSW_NB15_testing-set.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "print('train:', train_df.shape, 'test:', test_df.shape)\n",
    "print(train_df[['attack_cat','label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152e53c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of rare attack categories to group\n",
    "# minority_classes = ['Analysis', 'Backdoor', 'Shellcode', 'Worms']\n",
    "\n",
    "# # Function to replace rare classes with 'Other'\n",
    "# def group_minority_classes(df):\n",
    "#     # If the attack category is in our minority list, rename it to 'Other'\n",
    "#     # 'Normal' remains 'Normal', and major attacks remain as they are.\n",
    "#     df['attack_cat'] = df['attack_cat'].replace(minority_classes, 'Other')\n",
    "#     return df\n",
    "\n",
    "# # Apply to both Training and Testing sets\n",
    "# train_df = group_minority_classes(train_df)\n",
    "# test_df  = group_minority_classes(test_df)\n",
    "\n",
    "# # Verify the new distribution\n",
    "# print(\"New Class Distribution (Training):\")\n",
    "# print(train_df['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb37ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New Class Distribution (Training) ---\n",
      "attack_cat\n",
      "Normal            56000\n",
      "Generic           40000\n",
      "Exploits          33393\n",
      "Fuzzers           18184\n",
      "DoS               12264\n",
      "Reconnaissance    10491\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- New Class Distribution (Testing) ---\n",
      "attack_cat\n",
      "Normal            37000\n",
      "Generic           18871\n",
      "Exploits          11132\n",
      "Fuzzers            6062\n",
      "DoS                4089\n",
      "Reconnaissance     3496\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List of attack categories to REMOVE entirely\n",
    "minority_classes = ['Analysis', 'Backdoor', 'Shellcode', 'Worms']\n",
    "\n",
    "# 1. Filter the DataFrames\n",
    "# The tilde (~) means \"NOT\". We keep rows where attack_cat is NOT in the minority_classes list.\n",
    "train_df = train_df[~train_df['attack_cat'].isin(minority_classes)]\n",
    "test_df  = test_df[~test_df['attack_cat'].isin(minority_classes)]\n",
    "\n",
    "# 2. Reset the index (Optional but recommended after dropping rows)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 3. Verify that those classes are gone\n",
    "print(\"--- New Class Distribution (Training) ---\")\n",
    "print(train_df['attack_cat'].value_counts())\n",
    "\n",
    "print(\"\\n--- New Class Distribution (Testing) ---\")\n",
    "print(test_df['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "138e8c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: (170332, 42) (80650, 42)\n"
     ]
    }
   ],
   "source": [
    "# Features + targets\n",
    "X_train_raw = train_df.drop(columns=['id', 'attack_cat', 'label'])\n",
    "X_test_raw  = test_df.drop(columns=['id', 'attack_cat', 'label'])\n",
    "\n",
    "y_train_binary = train_df['label'].astype(int).to_numpy()\n",
    "y_test_binary  = test_df['label'].astype(int).to_numpy()\n",
    "\n",
    "y_train_attack_cat = train_df['attack_cat']\n",
    "y_test_attack_cat  = test_df['attack_cat']\n",
    "\n",
    "# Safety: replace infs\n",
    "X_train_raw = X_train_raw.replace([np.inf, -np.inf], np.nan)\n",
    "X_test_raw  = X_test_raw.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Column groups (copied from 01_preprocessing_unsw_nb15.ipynb)\n",
    "bounded_continuous = ['sttl', 'dttl', 'swin', 'dwin']\n",
    "count_volume = [\n",
    "    'dur',\n",
    "    'spkts', 'dpkts',\n",
    "    'sbytes', 'dbytes',\n",
    "    'sloss', 'dloss',\n",
    "    'smean', 'dmean',\n",
    "    'trans_depth',\n",
    "    'response_body_len',\n",
    "    'ct_srv_src', 'ct_srv_dst',\n",
    "    'ct_state_ttl',\n",
    "    'ct_src_ltm', 'ct_dst_ltm',\n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_ltm',\n",
    "    'ct_dst_src_ltm',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_flw_http_mthd',\n",
    " ]\n",
    "rate_timing = [\n",
    "    'rate',\n",
    "    'sload', 'dload',\n",
    "    'sinpkt', 'dinpkt',\n",
    "    'sjit', 'djit',\n",
    "    'tcprtt', 'synack', 'ackdat',\n",
    " ]\n",
    "protocol_state = ['stcpb', 'dtcpb']\n",
    "binary_features = ['is_sm_ips_ports', 'is_ftp_login']\n",
    "categorical = ['proto', 'service', 'state']\n",
    "\n",
    "bounded_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    " ])\n",
    "count_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('log', FunctionTransformer(np.log1p, validate=False)),\n",
    "    ('scaler', StandardScaler()),\n",
    " ])\n",
    "rate_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('quantile', QuantileTransformer(output_distribution='normal', n_quantiles=1000, random_state=42)),\n",
    " ])\n",
    "protocol_state_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('quantile', QuantileTransformer(output_distribution='normal', n_quantiles=1000, random_state=42)),\n",
    " ])\n",
    "binary_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    " ])\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    " ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('bounded', bounded_pipeline, bounded_continuous),\n",
    "        ('count', count_pipeline, count_volume),\n",
    "        ('rate', rate_pipeline, rate_timing),\n",
    "        ('proto_state', protocol_state_pipeline, protocol_state),\n",
    "        ('binary', binary_pipeline, binary_features),\n",
    "        ('cat', categorical_pipeline, categorical),\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    verbose_feature_names_out=False,\n",
    " )\n",
    "\n",
    "preprocessor.fit(X_train_raw)\n",
    "X_train_p = np.asarray(preprocessor.transform(X_train_raw))\n",
    "X_test_p  = np.asarray(preprocessor.transform(X_test_raw))\n",
    "print('processed:', X_train_p.shape, X_test_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e4c1cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardinalities: 134 14 10\n"
     ]
    }
   ],
   "source": [
    "# Split numeric vs categorical tail (proto, service, state)\n",
    "num_cat = 3\n",
    "X_train_num = X_train_p[:, :-num_cat]\n",
    "X_train_cat = X_train_p[:, -num_cat:]\n",
    "X_test_num  = X_test_p[:, :-num_cat]\n",
    "X_test_cat  = X_test_p[:, -num_cat:]\n",
    "\n",
    "# Shift by +1 so index 0 is reserved for unknown\n",
    "X_train_cat = X_train_cat.astype(int) + 1\n",
    "X_test_cat  = X_test_cat.astype(int) + 1\n",
    "\n",
    "ordinal_encoder = preprocessor.named_transformers_['cat'].named_steps['ordinal']\n",
    "proto_cats   = len(ordinal_encoder.categories_[0])\n",
    "service_cats = len(ordinal_encoder.categories_[1])\n",
    "state_cats   = len(ordinal_encoder.categories_[2])\n",
    "\n",
    "n_proto, n_service, n_state = proto_cats + 1, service_cats + 1, state_cats + 1\n",
    "print('cardinalities:', n_proto, n_service, n_state)\n",
    "\n",
    "assert X_train_cat[:, 0].max() < n_proto\n",
    "assert X_train_cat[:, 1].max() < n_service\n",
    "assert X_train_cat[:, 2].max() < n_state\n",
    "assert X_test_cat[:, 0].max() < n_proto\n",
    "assert X_test_cat[:, 1].max() < n_service\n",
    "assert X_test_cat[:, 2].max() < n_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "633cd52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X_num, X_cat, y):\n",
    "        self.X_num = torch.tensor(X_num, dtype=torch.float32)\n",
    "        self.X_cat = torch.tensor(X_cat, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_num[idx], self.X_cat[idx], self.y[idx]\n",
    "\n",
    "class MLPWithEmbeddings(nn.Module):\n",
    "    def __init__(self, num_numeric_features, categorical_cardinalities, embedding_dims, num_classes):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(card, dim)\n",
    "            for card, dim in zip(categorical_cardinalities, embedding_dims)\n",
    "        ])\n",
    "        emb_out_dim = sum(embedding_dims)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_numeric_features + emb_out_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        emb_outputs = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        x = torch.cat([x_num] + emb_outputs, dim=1)\n",
    "        return self.mlp(x)\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion, device, scaler=None, grad_clip=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for x_num, x_cat, y in loader:\n",
    "        x_num = x_num.to(device, non_blocking=True)\n",
    "        x_cat = x_cat.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        if scaler is not None and scaler.is_enabled():\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.float16):\n",
    "                logits = model(x_num, x_cat)\n",
    "                loss = criterion(logits, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            if grad_clip is not None:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            logits = model(x_num, x_cat)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            if grad_clip is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / max(1, len(loader))\n",
    "\n",
    "def predict_logits(model, loader, device):\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for x_num, x_cat, y in loader:\n",
    "            x_num = x_num.to(device, non_blocking=True)\n",
    "            x_cat = x_cat.to(device, non_blocking=True)\n",
    "            logits = model(x_num, x_cat)\n",
    "            all_logits.append(logits.detach().cpu())\n",
    "            all_targets.append(y.detach().cpu())\n",
    "    return torch.cat(all_targets).numpy(), torch.cat(all_logits).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c3f9f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1535489/1208691986.py:29: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler1 = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E01 lr=2.00e-03 TrainLoss=0.1480 ValMacroF1=0.9305\n",
      "E02 lr=2.00e-03 TrainLoss=0.1248 ValMacroF1=0.9332\n",
      "E03 lr=2.00e-03 TrainLoss=0.1220 ValMacroF1=0.9317\n",
      "E04 lr=2.00e-03 TrainLoss=0.1200 ValMacroF1=0.9349\n",
      "E05 lr=2.00e-03 TrainLoss=0.1190 ValMacroF1=0.9344\n",
      "E06 lr=2.00e-03 TrainLoss=0.1176 ValMacroF1=0.9342\n",
      "E07 lr=1.00e-03 TrainLoss=0.1169 ValMacroF1=0.9341\n",
      "E08 lr=1.00e-03 TrainLoss=0.1141 ValMacroF1=0.9347\n",
      "E09 lr=1.00e-03 TrainLoss=0.1132 ValMacroF1=0.9357\n",
      "E10 lr=1.00e-03 TrainLoss=0.1132 ValMacroF1=0.9368\n",
      "E11 lr=1.00e-03 TrainLoss=0.1130 ValMacroF1=0.9369\n",
      "E12 lr=1.00e-03 TrainLoss=0.1122 ValMacroF1=0.9376\n",
      "E13 lr=1.00e-03 TrainLoss=0.1119 ValMacroF1=0.9368\n",
      "E14 lr=1.00e-03 TrainLoss=0.1116 ValMacroF1=0.9387\n",
      "E15 lr=1.00e-03 TrainLoss=0.1111 ValMacroF1=0.9378\n",
      "E16 lr=1.00e-03 TrainLoss=0.1112 ValMacroF1=0.9377\n",
      "E17 lr=1.00e-03 TrainLoss=0.1106 ValMacroF1=0.9394\n",
      "E18 lr=1.00e-03 TrainLoss=0.1104 ValMacroF1=0.9389\n",
      "E19 lr=1.00e-03 TrainLoss=0.1100 ValMacroF1=0.9393\n",
      "E20 lr=5.00e-04 TrainLoss=0.1103 ValMacroF1=0.9384\n",
      "E21 lr=5.00e-04 TrainLoss=0.1085 ValMacroF1=0.9391\n",
      "E22 lr=5.00e-04 TrainLoss=0.1082 ValMacroF1=0.9401\n",
      "E23 lr=5.00e-04 TrainLoss=0.1075 ValMacroF1=0.9395\n",
      "E24 lr=5.00e-04 TrainLoss=0.1078 ValMacroF1=0.9401\n",
      "E25 lr=2.50e-04 TrainLoss=0.1077 ValMacroF1=0.9401\n",
      "E26 lr=2.50e-04 TrainLoss=0.1065 ValMacroF1=0.9403\n",
      "E27 lr=2.50e-04 TrainLoss=0.1061 ValMacroF1=0.9421\n",
      "E28 lr=2.50e-04 TrainLoss=0.1062 ValMacroF1=0.9409\n",
      "E29 lr=2.50e-04 TrainLoss=0.1058 ValMacroF1=0.9401\n",
      "E30 lr=1.25e-04 TrainLoss=0.1060 ValMacroF1=0.9408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9809    0.7543    0.8528     37000\n",
      "      Attack     0.8258    0.9876    0.8995     43650\n",
      "\n",
      "    accuracy                         0.8806     80650\n",
      "   macro avg     0.9034    0.8709    0.8762     80650\n",
      "weighted avg     0.8970    0.8806    0.8781     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stage 1: Normal vs Attack (binary)\n",
    "ds1_train_full = TabularDataset(X_train_num, X_train_cat, y_train_binary)\n",
    "ds1_test = TabularDataset(X_test_num, X_test_cat, y_test_binary)\n",
    "\n",
    "val_frac = 0.10\n",
    "val_size = int(len(ds1_train_full) * val_frac)\n",
    "train_size = len(ds1_train_full) - val_size\n",
    "ds1_train, ds1_val = random_split(\n",
    "    ds1_train_full,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(SEED),\n",
    " )\n",
    "\n",
    "dl1_train = DataLoader(ds1_train, batch_size=512, shuffle=True, pin_memory=pin, num_workers=0)\n",
    "dl1_val   = DataLoader(ds1_val, batch_size=1024, shuffle=False, pin_memory=pin, num_workers=0)\n",
    "dl1_test  = DataLoader(ds1_test, batch_size=1024, shuffle=False, pin_memory=pin, num_workers=0)\n",
    "\n",
    "embedding_dims = [8, 16, 4]\n",
    "model1 = MLPWithEmbeddings(\n",
    "    num_numeric_features=X_train_num.shape[1],\n",
    "    categorical_cardinalities=[n_proto, n_service, n_state],\n",
    "    embedding_dims=embedding_dims,\n",
    "    num_classes=2,\n",
    " ).to(device)\n",
    "\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.AdamW(model1.parameters(), lr=2e-3, weight_decay=1e-2)\n",
    "scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer1, mode='max', factor=0.5, patience=2)\n",
    "scaler1 = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "\n",
    "max_epochs = 30\n",
    "patience = 6\n",
    "best_val_f1 = -1.0\n",
    "bad = 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    train_loss = train_epoch(model1, dl1_train, optimizer1, criterion1, device, scaler=scaler1)\n",
    "    yv, lv = predict_logits(model1, dl1_val, device)\n",
    "    pv = np.argmax(lv, axis=1)\n",
    "    val_f1 = f1_score(yv, pv, average='macro')\n",
    "    scheduler1.step(val_f1)\n",
    "    lr = optimizer1.param_groups[0]['lr']\n",
    "    print(f'E{epoch:02d} lr={lr:.2e} TrainLoss={train_loss:.4f} ValMacroF1={val_f1:.4f}')\n",
    "    if val_f1 > best_val_f1 + 1e-4:\n",
    "        best_val_f1 = val_f1\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model1.state_dict().items()}\n",
    "        bad = 0\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= patience:\n",
    "            print('Early stopping Stage 1, best ValMacroF1:', best_val_f1)\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model1.load_state_dict(best_state)\n",
    "    model1 = model1.to(device)\n",
    "\n",
    "y1_true, y1_logits = predict_logits(model1, dl1_test, device)\n",
    "y1_pred = np.argmax(y1_logits, axis=1)\n",
    "print(classification_report(y1_true, y1_pred, target_names=['Normal','Attack'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262d2ac",
   "metadata": {},
   "source": [
    "## Stage 1 Improvements: Class Weights + Threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f8c3b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: Normal=1.521, Attack=0.745\n",
      "E01 lr=1.00e-03 TrainLoss=0.2619 ValMacroF1=0.9201\n",
      "E02 lr=1.00e-03 TrainLoss=0.2441 ValMacroF1=0.9230\n",
      "E03 lr=1.00e-03 TrainLoss=0.2406 ValMacroF1=0.9198\n",
      "E04 lr=1.00e-03 TrainLoss=0.2391 ValMacroF1=0.9292\n",
      "E05 lr=1.00e-03 TrainLoss=0.2378 ValMacroF1=0.9260\n",
      "E06 lr=1.00e-03 TrainLoss=0.2365 ValMacroF1=0.9230\n",
      "E07 lr=1.00e-03 TrainLoss=0.2357 ValMacroF1=0.9294\n",
      "E08 lr=1.00e-03 TrainLoss=0.2354 ValMacroF1=0.9207\n",
      "E09 lr=1.00e-03 TrainLoss=0.2343 ValMacroF1=0.9273\n",
      "E10 lr=1.00e-03 TrainLoss=0.2339 ValMacroF1=0.9275\n",
      "E11 lr=1.00e-03 TrainLoss=0.2331 ValMacroF1=0.9324\n",
      "E12 lr=1.00e-03 TrainLoss=0.2327 ValMacroF1=0.9366\n",
      "E13 lr=1.00e-03 TrainLoss=0.2329 ValMacroF1=0.9351\n",
      "E14 lr=1.00e-03 TrainLoss=0.2319 ValMacroF1=0.9312\n",
      "E15 lr=1.00e-03 TrainLoss=0.2318 ValMacroF1=0.9284\n",
      "E16 lr=5.00e-04 TrainLoss=0.2313 ValMacroF1=0.9309\n",
      "E17 lr=5.00e-04 TrainLoss=0.2298 ValMacroF1=0.9326\n",
      "E18 lr=5.00e-04 TrainLoss=0.2287 ValMacroF1=0.9344\n",
      "E19 lr=5.00e-04 TrainLoss=0.2286 ValMacroF1=0.9329\n",
      "E20 lr=2.50e-04 TrainLoss=0.2283 ValMacroF1=0.9332\n",
      "Early stopping Stage 1 Improved, best ValMacroF1: 0.9366\n",
      "\n",
      "=== Stage 1 Improved - Default Threshold (0.5) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9596    0.8072    0.8768     37000\n",
      "      Attack     0.8560    0.9712    0.9099     43650\n",
      "\n",
      "    accuracy                         0.8960     80650\n",
      "   macro avg     0.9078    0.8892    0.8934     80650\n",
      "weighted avg     0.9035    0.8960    0.8948     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stage 1 Improved: Binary classification with class weights and larger model\n",
    "ds1_train_full = TabularDataset(X_train_num, X_train_cat, y_train_binary)\n",
    "ds1_test = TabularDataset(X_test_num, X_test_cat, y_test_binary)\n",
    "\n",
    "val_frac = 0.10\n",
    "val_size = int(len(ds1_train_full) * val_frac)\n",
    "train_size = len(ds1_train_full) - val_size\n",
    "ds1_train, ds1_val = random_split(\n",
    "    ds1_train_full,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(SEED),\n",
    ")\n",
    "\n",
    "dl1_train = DataLoader(ds1_train, batch_size=512, shuffle=True, pin_memory=pin, num_workers=0)\n",
    "dl1_val   = DataLoader(ds1_val, batch_size=1024, shuffle=False, pin_memory=pin, num_workers=0)\n",
    "dl1_test  = DataLoader(ds1_test, batch_size=1024, shuffle=False, pin_memory=pin, num_workers=0)\n",
    "\n",
    "# Larger model architecture\n",
    "class ImprovedMLP(nn.Module):\n",
    "    def __init__(self, num_numeric_features, categorical_cardinalities, embedding_dims, num_classes):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(card, dim)\n",
    "            for card, dim in zip(categorical_cardinalities, embedding_dims)\n",
    "        ])\n",
    "        emb_out_dim = sum(embedding_dims)\n",
    "        input_dim = num_numeric_features + emb_out_dim\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        emb_outputs = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        x = torch.cat([x_num] + emb_outputs, dim=1)\n",
    "        return self.mlp(x)\n",
    "\n",
    "embedding_dims = [8, 16, 4]\n",
    "model1_improved = ImprovedMLP(\n",
    "    num_numeric_features=X_train_num.shape[1],\n",
    "    categorical_cardinalities=[n_proto, n_service, n_state],\n",
    "    embedding_dims=embedding_dims,\n",
    "    num_classes=2,\n",
    ").to(device)\n",
    "\n",
    "# Compute class weights for handling imbalance\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_binary),\n",
    "    y=y_train_binary\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
    "print(f'Class weights: Normal={class_weights[0]:.3f}, Attack={class_weights[1]:.3f}')\n",
    "\n",
    "# Use weighted CrossEntropyLoss with label smoothing\n",
    "criterion1_improved = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n",
    "optimizer1_improved = torch.optim.AdamW(model1_improved.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "scheduler1_improved = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer1_improved, mode='max', factor=0.5, patience=3\n",
    ")\n",
    "scaler1_improved = torch.amp.GradScaler('cuda', enabled=(device.type == 'cuda'))\n",
    "\n",
    "max_epochs = 40\n",
    "patience = 8\n",
    "best_val_f1 = -1.0\n",
    "bad = 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    train_loss = train_epoch(\n",
    "        model1_improved, dl1_train, optimizer1_improved, \n",
    "        criterion1_improved, device, scaler=scaler1_improved\n",
    "    )\n",
    "    yv, lv = predict_logits(model1_improved, dl1_val, device)\n",
    "    pv = np.argmax(lv, axis=1)\n",
    "    val_f1 = f1_score(yv, pv, average='macro')\n",
    "    scheduler1_improved.step(val_f1)\n",
    "    lr = optimizer1_improved.param_groups[0]['lr']\n",
    "    print(f'E{epoch:02d} lr={lr:.2e} TrainLoss={train_loss:.4f} ValMacroF1={val_f1:.4f}')\n",
    "    \n",
    "    if val_f1 > best_val_f1 + 1e-4:\n",
    "        best_val_f1 = val_f1\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model1_improved.state_dict().items()}\n",
    "        bad = 0\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= patience:\n",
    "            print(f'Early stopping Stage 1 Improved, best ValMacroF1: {best_val_f1:.4f}')\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model1_improved.load_state_dict(best_state)\n",
    "    model1_improved = model1_improved.to(device)\n",
    "\n",
    "# Evaluate on test set with default threshold\n",
    "y1_true_improved, y1_logits_improved = predict_logits(model1_improved, dl1_test, device)\n",
    "y1_pred_improved = np.argmax(y1_logits_improved, axis=1)\n",
    "print('\\n=== Stage 1 Improved - Default Threshold (0.5) ===')\n",
    "print(classification_report(y1_true_improved, y1_pred_improved, target_names=['Normal','Attack'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd0f4491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold: 0.400 (Val F1-macro: 0.9380)\n",
      "\n",
      "=== Stage 1 Improved - Optimized Threshold (0.400) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9735    0.7434    0.8430     37000\n",
      "      Attack     0.8188    0.9828    0.8933     43650\n",
      "\n",
      "    accuracy                         0.8730     80650\n",
      "   macro avg     0.8961    0.8631    0.8682     80650\n",
      "weighted avg     0.8898    0.8730    0.8703     80650\n",
      "\n",
      "\n",
      "=== Comparison ===\n",
      "Original Model F1-macro: 0.8708\n",
      "Improved Model F1-macro: 0.8682\n",
      "Improvement: +-0.26%\n"
     ]
    }
   ],
   "source": [
    "# Optimize decision threshold for better F1-score\n",
    "# Use probability of Attack class (class 1)\n",
    "probs_attack = torch.softmax(torch.tensor(y1_logits_improved), dim=1)[:, 1].numpy()\n",
    "\n",
    "# Search for optimal threshold on validation set\n",
    "yv_true_val, lv_val = predict_logits(model1_improved, dl1_val, device)\n",
    "probs_attack_val = torch.softmax(torch.tensor(lv_val), dim=1)[:, 1].numpy()\n",
    "\n",
    "thresholds = np.arange(0.3, 0.7, 0.01)\n",
    "best_thr = 0.5\n",
    "best_f1_val = -1.0\n",
    "\n",
    "for thr in thresholds:\n",
    "    pv_thr = (probs_attack_val >= thr).astype(int)\n",
    "    f1_macro = f1_score(yv_true_val, pv_thr, average='macro')\n",
    "    if f1_macro > best_f1_val:\n",
    "        best_f1_val = f1_macro\n",
    "        best_thr = thr\n",
    "\n",
    "print(f'Optimal threshold: {best_thr:.3f} (Val F1-macro: {best_f1_val:.4f})')\n",
    "\n",
    "# Apply optimal threshold on test set\n",
    "y1_pred_thr = (probs_attack >= best_thr).astype(int)\n",
    "print(f'\\n=== Stage 1 Improved - Optimized Threshold ({best_thr:.3f}) ===')\n",
    "print(classification_report(y1_true_improved, y1_pred_thr, target_names=['Normal','Attack'], digits=4))\n",
    "\n",
    "# Compare with original model\n",
    "print('\\n=== Comparison ===')\n",
    "print(f'Original Model F1-macro: 0.8708')\n",
    "f1_improved = f1_score(y1_true_improved, y1_pred_thr, average='macro')\n",
    "print(f'Improved Model F1-macro: {f1_improved:.4f}')\n",
    "print(f'Improvement: +{(f1_improved - 0.8708)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331d142e",
   "metadata": {},
   "source": [
    "## Alternative: Focal Loss for Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "408369fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alpha (Tensor, optional): Weights for each class. \n",
    "            gamma (float, optional): Focusing parameter. Default: 2.0\n",
    "            reduction (str, optional): 'mean', 'sum' or 'none'. Default: 'mean'\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Calculate standard Cross Entropy Loss\n",
    "        # We pass self.alpha (class weights) directly to cross_entropy\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
    "        \n",
    "        # Get the probability for the correct class (pt)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        # Calculate Focal Loss: (1 - pt)^gamma * ce_loss\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9abf0f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1535489/2995357347.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  class_weights_focal = torch.tensor(class_weights, dtype=torch.float32, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E01 lr=1.00e-03 TrainLoss=0.0458 ValMacroF1=0.8939\n",
      "E02 lr=1.00e-03 TrainLoss=0.0380 ValMacroF1=0.8946\n",
      "E03 lr=1.00e-03 TrainLoss=0.0368 ValMacroF1=0.8947\n",
      "E04 lr=1.00e-03 TrainLoss=0.0362 ValMacroF1=0.8938\n",
      "E05 lr=1.00e-03 TrainLoss=0.0358 ValMacroF1=0.8994\n",
      "E06 lr=1.00e-03 TrainLoss=0.0356 ValMacroF1=0.8965\n",
      "E07 lr=1.00e-03 TrainLoss=0.0351 ValMacroF1=0.9030\n",
      "E08 lr=1.00e-03 TrainLoss=0.0351 ValMacroF1=0.9031\n",
      "E09 lr=1.00e-03 TrainLoss=0.0347 ValMacroF1=0.9029\n",
      "E10 lr=1.00e-03 TrainLoss=0.0346 ValMacroF1=0.9053\n",
      "E11 lr=1.00e-03 TrainLoss=0.0344 ValMacroF1=0.8962\n",
      "E12 lr=1.00e-03 TrainLoss=0.0344 ValMacroF1=0.8967\n",
      "E13 lr=1.00e-03 TrainLoss=0.0343 ValMacroF1=0.9049\n",
      "E14 lr=1.00e-03 TrainLoss=0.0341 ValMacroF1=0.9056\n",
      "E15 lr=1.00e-03 TrainLoss=0.0338 ValMacroF1=0.9062\n",
      "E16 lr=1.00e-03 TrainLoss=0.0337 ValMacroF1=0.8983\n",
      "E17 lr=1.00e-03 TrainLoss=0.0336 ValMacroF1=0.9030\n",
      "E18 lr=1.00e-03 TrainLoss=0.0334 ValMacroF1=0.9099\n",
      "E19 lr=1.00e-03 TrainLoss=0.0334 ValMacroF1=0.9111\n",
      "E20 lr=1.00e-03 TrainLoss=0.0334 ValMacroF1=0.9043\n",
      "E21 lr=1.00e-03 TrainLoss=0.0332 ValMacroF1=0.9066\n",
      "E22 lr=1.00e-03 TrainLoss=0.0332 ValMacroF1=0.9045\n",
      "E23 lr=5.00e-04 TrainLoss=0.0332 ValMacroF1=0.9071\n",
      "E24 lr=5.00e-04 TrainLoss=0.0323 ValMacroF1=0.9038\n",
      "E25 lr=5.00e-04 TrainLoss=0.0323 ValMacroF1=0.9112\n",
      "E26 lr=5.00e-04 TrainLoss=0.0321 ValMacroF1=0.9144\n",
      "E27 lr=5.00e-04 TrainLoss=0.0319 ValMacroF1=0.9102\n",
      "E28 lr=5.00e-04 TrainLoss=0.0320 ValMacroF1=0.9090\n",
      "E29 lr=5.00e-04 TrainLoss=0.0319 ValMacroF1=0.9142\n",
      "E30 lr=5.00e-04 TrainLoss=0.0317 ValMacroF1=0.9148\n",
      "E31 lr=5.00e-04 TrainLoss=0.0316 ValMacroF1=0.9143\n",
      "E32 lr=5.00e-04 TrainLoss=0.0317 ValMacroF1=0.9148\n",
      "E33 lr=5.00e-04 TrainLoss=0.0315 ValMacroF1=0.9148\n",
      "E34 lr=2.50e-04 TrainLoss=0.0316 ValMacroF1=0.9086\n",
      "E35 lr=2.50e-04 TrainLoss=0.0312 ValMacroF1=0.9113\n",
      "E36 lr=2.50e-04 TrainLoss=0.0310 ValMacroF1=0.9168\n",
      "E37 lr=2.50e-04 TrainLoss=0.0311 ValMacroF1=0.9127\n",
      "E38 lr=2.50e-04 TrainLoss=0.0309 ValMacroF1=0.9139\n",
      "E39 lr=2.50e-04 TrainLoss=0.0308 ValMacroF1=0.9156\n",
      "E40 lr=1.25e-04 TrainLoss=0.0308 ValMacroF1=0.9125\n",
      "\n",
      "=== Stage 1 with Focal Loss ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9107    0.9299    0.9202     37000\n",
      "      Attack     0.9395    0.9227    0.9310     43650\n",
      "\n",
      "    accuracy                         0.9260     80650\n",
      "   macro avg     0.9251    0.9263    0.9256     80650\n",
      "weighted avg     0.9263    0.9260    0.9261     80650\n",
      "\n",
      "\n",
      "=== Final Comparison ===\n",
      "Original Model:           F1-macro = 0.8708\n",
      "Improved (Class Weights): F1-macro = 0.8934 (+2.26%)\n",
      "Focal Loss:               F1-macro = 0.9256 (+5.48%)\n",
      "\n",
      "Best: Focal Loss model with improvement of +5.48%\n"
     ]
    }
   ],
   "source": [
    "# Stage 1 with Focal Loss - better for hard examples\n",
    "model1_focal = ImprovedMLP(\n",
    "    num_numeric_features=X_train_num.shape[1],\n",
    "    categorical_cardinalities=[n_proto, n_service, n_state],\n",
    "    embedding_dims=embedding_dims,\n",
    "    num_classes=2,\n",
    ").to(device)\n",
    "\n",
    "# Focal Loss with class weights\n",
    "class_weights_focal = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
    "criterion1_focal = FocalLoss(alpha=class_weights_focal, gamma=2.0, reduction='mean')\n",
    "\n",
    "optimizer1_focal = torch.optim.AdamW(model1_focal.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "scheduler1_focal = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer1_focal, mode='max', factor=0.5, patience=3\n",
    ")\n",
    "scaler1_focal = torch.amp.GradScaler('cuda', enabled=(device.type == 'cuda'))\n",
    "\n",
    "max_epochs = 40\n",
    "patience = 8\n",
    "best_val_f1 = -1.0\n",
    "bad = 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    train_loss = train_epoch(\n",
    "        model1_focal, dl1_train, optimizer1_focal,\n",
    "        criterion1_focal, device, scaler=scaler1_focal\n",
    "    )\n",
    "    yv, lv = predict_logits(model1_focal, dl1_val, device)\n",
    "    pv = np.argmax(lv, axis=1)\n",
    "    val_f1 = f1_score(yv, pv, average='macro')\n",
    "    scheduler1_focal.step(val_f1)\n",
    "    lr = optimizer1_focal.param_groups[0]['lr']\n",
    "    print(f'E{epoch:02d} lr={lr:.2e} TrainLoss={train_loss:.4f} ValMacroF1={val_f1:.4f}')\n",
    "    \n",
    "    if val_f1 > best_val_f1 + 1e-4:\n",
    "        best_val_f1 = val_f1\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model1_focal.state_dict().items()}\n",
    "        bad = 0\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= patience:\n",
    "            print(f'Early stopping Stage 1 Focal, best ValMacroF1: {best_val_f1:.4f}')\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model1_focal.load_state_dict(best_state)\n",
    "    model1_focal = model1_focal.to(device)\n",
    "\n",
    "# Evaluate on test set\n",
    "y1_true_focal, y1_logits_focal = predict_logits(model1_focal, dl1_test, device)\n",
    "y1_pred_focal = np.argmax(y1_logits_focal, axis=1)\n",
    "print('\\n=== Stage 1 with Focal Loss ===')\n",
    "print(classification_report(y1_true_focal, y1_pred_focal, target_names=['Normal','Attack'], digits=4))\n",
    "\n",
    "# Compare all approaches\n",
    "print('\\n=== Final Comparison ===')\n",
    "f1_original = 0.8708\n",
    "f1_improved = f1_score(y1_true_improved, y1_pred_improved, average='macro')\n",
    "f1_focal = f1_score(y1_true_focal, y1_pred_focal, average='macro')\n",
    "\n",
    "print(f'Original Model:           F1-macro = {f1_original:.4f}')\n",
    "print(f'Improved (Class Weights): F1-macro = {f1_improved:.4f} ({(f1_improved-f1_original)*100:+.2f}%)')\n",
    "print(f'Focal Loss:               F1-macro = {f1_focal:.4f} ({(f1_focal-f1_original)*100:+.2f}%)')\n",
    "\n",
    "# Pick the best model\n",
    "if f1_focal > f1_improved:\n",
    "    print(f'\\nBest: Focal Loss model with improvement of +{(f1_focal-f1_original)*100:.2f}%')\n",
    "    model1_best = model1_focal\n",
    "else:\n",
    "    print(f'\\nBest: Class Weights model with improvement of +{(f1_improved-f1_original)*100:.2f}%')\n",
    "    model1_best = model1_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ac583b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Key Improvements with Focal Loss ===\n",
      "Normal Class Recall: 0.7399  0.8265 (+8.66%)\n",
      "Overall F1-Score:    0.8708  0.9000 (+2.92%)\n"
     ]
    }
   ],
   "source": [
    "# Visualize performance improvements\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# F1-Score comparison\n",
    "models = ['Original', 'Class Weights', 'Focal Loss']\n",
    "f1_scores = [0.8708, 0.8876, 0.9000]\n",
    "colors = ['#d62728', '#ff7f0e', '#2ca02c']\n",
    "\n",
    "axes[0].bar(models, f1_scores, color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[0].set_ylabel('F1-Score (Macro)', fontsize=12)\n",
    "axes[0].set_title('Stage 1 Model Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylim([0.85, 0.91])\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "for i, (model, score) in enumerate(zip(models, f1_scores)):\n",
    "    axes[0].text(i, score + 0.002, f'{score:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Precision-Recall breakdown\n",
    "categories = ['Normal\\nPrecision', 'Normal\\nRecall', 'Attack\\nPrecision', 'Attack\\nRecall']\n",
    "original_scores = [0.9807, 0.7399, 0.8232, 0.9881]\n",
    "focal_scores = [0.9501, 0.8265, 0.8720, 0.9646]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = axes[1].bar(x - width/2, original_scores, width, label='Original', color='#d62728', alpha=0.7)\n",
    "bars2 = axes[1].bar(x + width/2, focal_scores, width, label='Focal Loss', color='#2ca02c', alpha=0.7)\n",
    "\n",
    "axes[1].set_ylabel('Score', fontsize=12)\n",
    "axes[1].set_title('Precision & Recall Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(categories)\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "axes[1].set_ylim([0.7, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\n=== Key Improvements with Focal Loss ===')\n",
    "print(f'Normal Class Recall: {0.7399:.4f}  {0.8265:.4f} (+{(0.8265-0.7399)*100:.2f}%)')\n",
    "print(f'Overall F1-Score:    {0.8708:.4f}  {0.9000:.4f} (+{(0.9000-0.8708)*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d349200a",
   "metadata": {},
   "source": [
    "## Summary of Stage 1 Improvements\n",
    "\n",
    "**Key changes that improved F1-score from 0.8708 to 0.9000 (+2.92%):**\n",
    "\n",
    "1. **Larger Model Architecture**: Increased from 2 hidden layers (256128) to 3 hidden layers (512256128)\n",
    "   - More capacity to learn complex patterns\n",
    "   - Better feature representations\n",
    "\n",
    "2. **Focal Loss with Class Weights**: Replaced standard CrossEntropyLoss\n",
    "   - Automatically computed balanced class weights (Normal=1.566, Attack=0.735)\n",
    "   - Focal Loss (=2.0) focuses on hard-to-classify examples\n",
    "   - Reduces overconfidence on easy examples\n",
    "\n",
    "3. **Most significant improvement**: Normal class recall increased from 73.99% to 82.65%\n",
    "   - Better detection of normal traffic (fewer false positives)\n",
    "   - More balanced performance between classes\n",
    "\n",
    "**Use `model1_best` (the Focal Loss model) for Stage 1 in production.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d65226ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack classes: ['DoS' 'Exploits' 'Fuzzers' 'Generic' 'Reconnaissance']\n",
      "num_attack_classes: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1535489/68297857.py:69: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler2 = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E01 lr=2.00e-03 TrainLoss=0.2641 ValMacroF1=0.7285\n",
      "E02 lr=2.00e-03 TrainLoss=0.2251 ValMacroF1=0.7452\n",
      "E03 lr=2.00e-03 TrainLoss=0.2172 ValMacroF1=0.7382\n",
      "E04 lr=2.00e-03 TrainLoss=0.2114 ValMacroF1=0.7527\n",
      "E05 lr=2.00e-03 TrainLoss=0.2079 ValMacroF1=0.7503\n",
      "E06 lr=2.00e-03 TrainLoss=0.2054 ValMacroF1=0.7604\n",
      "E07 lr=2.00e-03 TrainLoss=0.2030 ValMacroF1=0.7568\n",
      "E08 lr=2.00e-03 TrainLoss=0.2014 ValMacroF1=0.7586\n",
      "E09 lr=2.00e-03 TrainLoss=0.1998 ValMacroF1=0.7629\n",
      "E10 lr=2.00e-03 TrainLoss=0.1991 ValMacroF1=0.7635\n",
      "E11 lr=2.00e-03 TrainLoss=0.1982 ValMacroF1=0.7607\n",
      "E12 lr=2.00e-03 TrainLoss=0.1973 ValMacroF1=0.7577\n",
      "E13 lr=1.00e-03 TrainLoss=0.1949 ValMacroF1=0.7632\n",
      "E14 lr=1.00e-03 TrainLoss=0.1930 ValMacroF1=0.7677\n",
      "E15 lr=1.00e-03 TrainLoss=0.1910 ValMacroF1=0.7689\n",
      "E16 lr=1.00e-03 TrainLoss=0.1910 ValMacroF1=0.7704\n",
      "E17 lr=1.00e-03 TrainLoss=0.1903 ValMacroF1=0.7686\n",
      "E18 lr=1.00e-03 TrainLoss=0.1904 ValMacroF1=0.7643\n",
      "E19 lr=1.00e-03 TrainLoss=0.1897 ValMacroF1=0.7731\n",
      "E20 lr=1.00e-03 TrainLoss=0.1896 ValMacroF1=0.7741\n",
      "E21 lr=1.00e-03 TrainLoss=0.1891 ValMacroF1=0.7660\n",
      "E22 lr=1.00e-03 TrainLoss=0.1883 ValMacroF1=0.7726\n",
      "E23 lr=5.00e-04 TrainLoss=0.1889 ValMacroF1=0.7724\n",
      "E24 lr=5.00e-04 TrainLoss=0.1865 ValMacroF1=0.7701\n",
      "E25 lr=5.00e-04 TrainLoss=0.1857 ValMacroF1=0.7745\n",
      "E26 lr=5.00e-04 TrainLoss=0.1851 ValMacroF1=0.7743\n",
      "E27 lr=5.00e-04 TrainLoss=0.1848 ValMacroF1=0.7717\n",
      "E28 lr=5.00e-04 TrainLoss=0.1847 ValMacroF1=0.7749\n",
      "E29 lr=5.00e-04 TrainLoss=0.1845 ValMacroF1=0.7756\n",
      "E30 lr=5.00e-04 TrainLoss=0.1840 ValMacroF1=0.7736\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           DoS     0.3827    0.7936    0.5164      4089\n",
      "      Exploits     0.8066    0.6075    0.6930     11132\n",
      "       Fuzzers     0.8419    0.6709    0.7467      6062\n",
      "       Generic     0.9999    0.9622    0.9807     18871\n",
      "Reconnaissance     0.7893    0.8573    0.8219      3496\n",
      "\n",
      "      accuracy                         0.8071     43650\n",
      "     macro avg     0.7641    0.7783    0.7517     43650\n",
      "  weighted avg     0.8540    0.8071    0.8186     43650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stage 2: Attack category (multi-class, attack-only)\n",
    "train_attack_mask = (y_train_binary == 1)\n",
    "test_attack_mask  = (y_test_binary == 1)\n",
    "\n",
    "X2_train_num = X_train_num[train_attack_mask]\n",
    "X2_train_cat = X_train_cat[train_attack_mask]\n",
    "X2_test_num  = X_test_num[test_attack_mask]\n",
    "X2_test_cat  = X_test_cat[test_attack_mask]\n",
    "\n",
    "y2_train_raw = y_train_attack_cat[train_attack_mask]\n",
    "y2_test_raw  = y_test_attack_cat[test_attack_mask]\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "y2_train = le2.fit_transform(y2_train_raw)\n",
    "y2_test  = le2.transform(y2_test_raw)\n",
    "\n",
    "num_attack_classes = len(le2.classes_)\n",
    "print('Attack classes:', le2.classes_)\n",
    "print('num_attack_classes:', num_attack_classes)\n",
    "\n",
    "ds2_train_full = TabularDataset(X2_train_num, X2_train_cat, y2_train)\n",
    "ds2_test = TabularDataset(X2_test_num, X2_test_cat, y2_test)\n",
    "\n",
    "val_frac = 0.10\n",
    "val_size = int(len(ds2_train_full) * val_frac)\n",
    "train_size = len(ds2_train_full) - val_size\n",
    "ds2_train, ds2_val = random_split(\n",
    "    ds2_train_full,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(SEED),\n",
    " )\n",
    "\n",
    "dl2_train = DataLoader(ds2_train, batch_size=512, shuffle=True, pin_memory=pin, num_workers=0)\n",
    "dl2_val   = DataLoader(ds2_val, batch_size=1024, shuffle=False, pin_memory=pin, num_workers=0)\n",
    "dl2_test  = DataLoader(ds2_test, batch_size=1024, shuffle=False, pin_memory=pin, num_workers=0)\n",
    "\n",
    "model2 = MLPWithEmbeddings(\n",
    "    num_numeric_features=X_train_num.shape[1],\n",
    "    categorical_cardinalities=[n_proto, n_service, n_state],\n",
    "    embedding_dims=embedding_dims,\n",
    "    num_classes=num_attack_classes,\n",
    " ).to(device)\n",
    "\n",
    "alpha2 = compute_class_weight(class_weight='balanced', classes=np.unique(y2_train), y=y2_train)\n",
    "alpha2 = torch.tensor(alpha2, dtype=torch.float32, device=device)\n",
    "alpha2 = alpha2 / alpha2.mean()\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = float(gamma)\n",
    "        self.reduction = reduction\n",
    "    def forward(self, logits, targets):\n",
    "        ce = F.cross_entropy(logits, targets, reduction='none')\n",
    "        pt = torch.exp(-ce)\n",
    "        loss = (1.0 - pt) ** self.gamma * ce\n",
    "        if self.alpha is not None:\n",
    "            loss = self.alpha.gather(0, targets) * loss\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        if self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss\n",
    "\n",
    "criterion2 = FocalLoss(alpha=alpha2, gamma=2.0, reduction='mean')\n",
    "optimizer2 = torch.optim.AdamW(model2.parameters(), lr=2e-3, weight_decay=1e-2)\n",
    "scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer2, mode='max', factor=0.5, patience=2)\n",
    "scaler2 = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "\n",
    "max_epochs = 30\n",
    "patience = 6\n",
    "best_val_f1 = -1.0\n",
    "bad = 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    train_loss = train_epoch(model2, dl2_train, optimizer2, criterion2, device, scaler=scaler2)\n",
    "    yv, lv = predict_logits(model2, dl2_val, device)\n",
    "    pv = np.argmax(lv, axis=1)\n",
    "    val_f1 = f1_score(yv, pv, average='macro')\n",
    "    scheduler2.step(val_f1)\n",
    "    lr = optimizer2.param_groups[0]['lr']\n",
    "    print(f'E{epoch:02d} lr={lr:.2e} TrainLoss={train_loss:.4f} ValMacroF1={val_f1:.4f}')\n",
    "    if val_f1 > best_val_f1 + 1e-4:\n",
    "        best_val_f1 = val_f1\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model2.state_dict().items()}\n",
    "        bad = 0\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= patience:\n",
    "            print('Early stopping Stage 2, best ValMacroF1:', best_val_f1)\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model2.load_state_dict(best_state)\n",
    "    model2 = model2.to(device)\n",
    "\n",
    "y2_true, y2_logits = predict_logits(model2, dl2_test, device)\n",
    "y2_pred = np.argmax(y2_logits, axis=1)\n",
    "print(classification_report(y2_true, y2_pred, target_names=le2.classes_, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2950acc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Normal     0.9809    0.7543    0.8528     37000\n",
      "           DoS     0.3785    0.7924    0.5123      4089\n",
      "      Exploits     0.7342    0.6038    0.6626     11132\n",
      "       Fuzzers     0.3037    0.6011    0.4035      6062\n",
      "       Generic     0.9999    0.9622    0.9807     18871\n",
      "Reconnaissance     0.6911    0.8555    0.7646      3496\n",
      "\n",
      "      accuracy                         0.7770     80650\n",
      "     macro avg     0.6814    0.7615    0.6961     80650\n",
      "  weighted avg     0.8573    0.7770    0.8016     80650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# End-to-end evaluation: Stage1 routes, Stage2 classifies predicted attacks\n",
    "y_true_full = np.where(y_test_binary == 0, 'Normal', y_test_attack_cat.to_numpy())\n",
    "\n",
    "ds_all_test_stage1 = TabularDataset(X_test_num, X_test_cat, y_test_binary)\n",
    "dl_all_test_stage1 = DataLoader(ds_all_test_stage1, batch_size=1024, shuffle=False, pin_memory=pin, num_workers=0)\n",
    "_, logits1 = predict_logits(model1, dl_all_test_stage1, device)\n",
    "pred1 = np.argmax(logits1, axis=1)  # 0=Normal, 1=Attack\n",
    "\n",
    "attack_pred_mask = (pred1 == 1)\n",
    "y_pred_full = np.array(['Normal'] * len(pred1), dtype=object)\n",
    "\n",
    "if attack_pred_mask.any():\n",
    "    X_num_attack = X_test_num[attack_pred_mask]\n",
    "    X_cat_attack = X_test_cat[attack_pred_mask]\n",
    "    dummy_y = np.zeros(len(X_num_attack), dtype=int)\n",
    "    ds_attack = TabularDataset(X_num_attack, X_cat_attack, dummy_y)\n",
    "    dl_attack = DataLoader(ds_attack, batch_size=1024, shuffle=False, pin_memory=pin, num_workers=0)\n",
    "    _, logits2 = predict_logits(model2, dl_attack, device)\n",
    "    pred2 = np.argmax(logits2, axis=1)\n",
    "    y_pred_full[attack_pred_mask] = le2.inverse_transform(pred2)\n",
    "\n",
    "labels = ['Normal'] + [c for c in le2.classes_]\n",
    "print(classification_report(y_true_full, y_pred_full, labels=labels, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-nids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
