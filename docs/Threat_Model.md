# ğŸ“‘ Red Team Operations Report: Vulnerability Assessment

## ğŸ¯ Target System
- **System**: Federated NIDS (UNSW-NB15)
- **Network Topology**: 40 Clients (IID Partition)
- **Aggregation Protocol**: FedAvg (Baseline) & Krum (Defense)

---

## 1ï¸âƒ£ Experiment A: Simple Data Poisoning (The Baseline)
### ğŸ•µï¸ The "Silent" Approach

### ğŸ“¥ The Inputs (Configuration)
- **Method**: The attacker injects a backdoor trigger into their local training data but sends a *standard* weight update to the server.
- **Poison Ratio**: 30% of the local batch  
- **Trigger**: Feature 0 set to `5.0`  
- **Target Label**: Class 0 (*Normal*)  
- **Scaling Factor**: `1.0` (No boosting)  
- **Honest Clients**: 39  
- **Malicious Clients**: 1  

### ğŸ“¤ The Outputs (Results)
- **Global Accuracy**: ~75% (Unaffected)  
- **Attack Success Rate (ASR)**: ~0 â€“ 1.5% âŒ (Failed)

### ğŸ”¬ Technical Analysis (Why it Failed)
This experiment demonstrated the **Dilution Effect** inherent in Federated Learning.

The server aggregates updates using a weighted average:

\[
W_{global} = W_{current} + \sum (\Delta W_i \times \frac{n_i}{N})
\]

- The attacker controlled only **1/40 â‰ˆ 2.5%** of the total contribution.
- **97.5% honest gradients** overwhelmed the malicious signal.
- Result: The backdoor was **washed out** before being learned.

---

## 2ï¸âƒ£ Experiment B: Model Replacement (The "Math Hack")
### ğŸ’£ The "Brute Force" Approach

### ğŸ“¥ The Inputs (Configuration)
- **Method**: The attacker mathematically cancels honest client updates.
- **Mechanism**: Scale update by  
  \[
  \frac{N}{\eta}
  \]
- **Poison Ratio**: 30%  
- **Aggressive Mode**: Enabled  
- **Scaling Factor**: `40Ã—`  
- **Target Defense**: FedAvg  

### ğŸ“¤ The Outputs (Results)
- **Global Accuracy**: ~39% âš ï¸ (System Crash)  
- **Attack Success Rate (ASR)**: **100%** âœ… (Total Compromise)

### ğŸ”¬ Technical Analysis (Why it Worked)
This attack exploited the **linearity of FedAvg**.

By multiplying the update by `40`, the aggregation becomes:

\[
W_{global} \approx W_{malicious}
\]

- The attacker **overwrote the global model** with their local model.
- **Victory**: Backdoor installed instantly.
- **Collateral Damage**:
  - The malicious model was trained on only `1/40` of the data.
  - Global accuracy dropped from **75% â†’ 39%**.

---

## 3ï¸âƒ£ Experiment C: Collusion Attack (The "Swarm")
### ğŸœ The "Strength in Numbers" Approach

### ğŸ“¥ The Inputs (Configuration)
- **Method**: Coordinated attack by multiple malicious clients.
- **Malicious Clients**: 4 (10% of the network)
- **Mechanism**: Backdoor injection + boosted weights
- **Target Defense**: Krum (Euclidean distanceâ€“based)

### ğŸ“¤ The Outputs (Results)
- **Global Accuracy**: ~66% (Degraded but functional)
- **Attack Success Rate (ASR)**: **76.34%** âœ… (Defense Bypassed)

### ğŸ”¬ Technical Analysis (Why Krum Failed)
- **Krum Strategy**: Selects the update closest to its neighbors.
- **Honest Clients**:
  - Naturally noisy updates
  - High variance (Ïƒ > 0)
- **Colluding Attackers**:
  - Sent **identical / tightly clustered** boosted updates

#### âš ï¸ The Flaw
- Krum interpreted the **malicious cluster** as consistent and trustworthy.
- Honest clients appeared as **dispersed noise**.
- Result: The malicious update was selected.

---

## 4ï¸âƒ£ Summary of Vulnerabilities

| Attack Type        | Target  | Outcome | Key Takeaway |
|--------------------|---------|---------|--------------|
| Simple Poisoning   | FedAvg  | âŒ Failed | FL resists small-scale noise (Dilution) |
| Model Replacement | FedAvg  | âœ… Success | Unbounded updates enable single-agent dominance |
| Collusion Attack  | Krum    | âœ… Success | Distance-based defenses fail against clustered attackers |

---

## 5ï¸âƒ£ The Current Standoff

### ğŸ›¡ï¸ Median Defense
- **Tested**: Coordinate-wise Median
- **Result**: ASR â‰ˆ 0% âœ… (All attacks blocked)

### ğŸ” Why Median Worked
- Treats **40Ã— boosted weights** as statistical outliers.
- Clips extreme values **regardless of clustering**.

### ğŸ¯ The Next Challenge
To defeat the Median defense:
- âŒ **Brute Force** attacks (Model Replacement) will not work.
- âœ… We must design a **Stealth Attack**:
  - **Projected Gradient Descent (PGD)**
  - Slowly shifts the median
  - Avoids detection as an outlier

---

## ğŸ§  Conclusion
This report concludes the analysis of **Brute Force and Collusion-based attacks**.  
The next phase focuses on **sophisticated stealth backdoor attacks** capable of bypassing **Median-based aggregation defenses**.
